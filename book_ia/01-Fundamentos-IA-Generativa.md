---
dg-publish: true
dg-path: 01-Fundamentos-IA-Generativa.md
cover: "![[Gemini_Generated_Image_byudq9byudq9byud.png]]"
tags:
  - proyecto-ia
resumen: Define qu√© es la ingenier√≠a de prompts y sus t√©cnicas principales para guiar a los modelos.
icono: üí°
estado: Borrador
---

# Cap√≠tulo 1: Fundamentos de la IA Generativa

Hasta hace apenas unos a√±os, hablar de inteligencia artificial (IA) era casi sin√≥nimo de ciencia ficci√≥n.¬† Hoy, en cambio, la IA ha comenzado a infiltrarse en nuestra vida cotidiana: forma parte de nuestras conversaciones, de lo que escribimos, influye en lo que vemos en redes sociales e incluso en los memes que compartimos. ¬øQu√© ha pasado para que ‚Äúesa cosa de los robots‚Äù se haya vuelto tan omnipresente?

Una de las claves est√° en el auge de los modelos generativos, especialmente los modelos de lenguaje de gran tama√±o (Large Language Models, LLM), presentes en chatbots como ChatGPT, DeepSeek o LeChat, entre otros. Estos sistemas son capaces de predecir la siguiente palabra en casi cualquier contexto, generando textos extensos, coherentes y, en muchos casos, indistinguibles de los escritos por una persona [(Achiam et¬†al. 2024)](https://www.zotero.org/google-docs/?SWGmZX).

Esta capacidad de generar contenido (raz√≥n por la cual tambi√©n se les conoce como IA generativa), les ha permitido tambi√©n resolver una amplia gama de pruebas de referencia estandarizadas [(Bengio et¬†al. 2025; Maslej 2025)](https://www.zotero.org/google-docs/?LCOFOp). Dichas pruebas consisten en desaf√≠os acad√©micos o t√©cnicos que ponen a prueba habilidades de razonamiento, comprensi√≥n y resoluci√≥n de problemas. En algunos casos, estos modelos han alcanzado tasas de √©xito superiores al 80%¬† y en campos como la visi√≥n por computadora, el reconocimiento de voz, las matem√°ticas o la inform√°tica, su desempe√±o iguala e incluso supera al humano [(Bengio et¬†al. 2025; Google DeepMind 2025a, 2025b; Maslej 2025; Trinh et¬†al. 2024)](https://www.zotero.org/google-docs/?WyAu7I).

Este impacto creciente tambi√©n est√° transformando la manera en que abordamos la investigaci√≥n acad√©mica. Por ello, para adentrarnos con confianza en el nuevo panorama de la investigaci√≥n acad√©mica asistida por IA generativa, es indispensable comenzar por lo fundamental:¬†comprender qu√© es esta tecnolog√≠a y c√≥mo funciona. 

Este cap√≠tulo sienta las bases conceptuales necesarias para ello. No buscamos ofrecer una exposici√≥n t√©cnica exhaustiva, sino proporcionar un marco de referencia claro y pr√°ctico para estudiantes, docentes e investigadores. A continuaci√≥n analizaremos desde la definici√≥n de la [[09-Glosario#IA Generativa|IA generativa]] y los modelos que la hacen posible, hasta los conceptos clave que determinan sus capacidades y limitaciones. Apropiarse de estos fundamentos resulta esencial para aprovechar al m√°ximo estas herramientas y saber cu√°ndo y c√≥mo integrarlas en nuestros proyectos de investigaci√≥n.

---


## 1.1 ¬øQu√© es la IA Generativa?

La IA generativa es un subcampo de la inteligencia artificial (ver Figura) que usa modelos capaces de producir contenido nuevo (texto, im√°genes, audio, video o c√≥digo) a partir de patrones aprendidos en enormes vol√∫menes de datos [(Chang et¬†al. 2024; Raschka 2024a; Xiao y Zhu 2025)](https://www.zotero.org/google-docs/?NxDja0). Ese salto fue lo que convirti√≥ a chatbots como ChatGPT, Gemini, Grok, Claude, Meta AI, DeepSeek, Qwen o Le Chat en asistentes vers√°tiles de uso diario. 

En etapas anteriores, los chatbots tradicionales se limitaban a respuestas preestablecidas para un n√∫mero reducido de preguntas. De forma similar, el aprendizaje autom√°tico cl√°sico se orientaba a problemas bien delimitados (clasificaci√≥n de im√°genes, detecci√≥n de spam, an√°lisis de sentimiento, etc.), de modo que cada tarea requer√≠a su propio modelo. No obstante, cuando se trataba de tareas ling√º√≠sticas que requer√≠an comprensi√≥n profunda y producci√≥n de texto (por ejemplo, analizar mensajes largos o generar contenidos originales coherentes y pertinentes al contexto) el desempe√±o era limitado. En la actualidad, un solo modelo generativo es capaz de adaptarse a una gran variedad de prop√≥sitos (por eso tambi√©n se les conoce como modelos multimodales [(Alammar y Grootendorst 2024; Raschka 2024b)]) sin requerir entrenamientos espec√≠ficos para cada tarea. Por ejemplo; procesan y traducen informaci√≥n, resumen y elaboran explicaciones did√°cticas; reescriben textos, ‚Äúentienden‚Äù y proponen ideas creativas; generan c√≥digo o contenido audiovisual; y describen im√°genes o videos, entre muchas otras funciones. De ah√≠ el entusiasmo de que estamos frente a un nuevo paradigma.

Cuando decimos que un modelo generativo (como es el caso de los LLM) ‚Äúentiende‚Äù o ‚Äúidea‚Äù, no hablamos de conciencia, compresi√≥n o creatividad humana. Hablamos de que procesa y genera texto coherente y √∫til en contexto. A veces parece que ‚Äúrazona‚Äù, pero lo que hay detr√°s es una predicci√≥n de la palabra m√°s probable que sigue a una secuencia anterior. Si escribes ‚ÄúLas quesadillas van con‚Ä¶‚Äù, el modelo calcula estad√≠sticamente cu√°l palabra tiene mayor probabilidad de aparecer despu√©s, por ejemplo, entre las palabras ‚Äúaguacate‚Äù, ‚Äúcebolla‚Äù, ..., o ‚Äúqueso‚Äù (ver Figura), ser√≠a ‚Äúqueso‚Äù la palabra m√°s probable¬† (la que m√°s aparece en los textos utilizados para entrenar el modelo). Esa simple tarea de predicci√≥n, repetida miles de millones de veces, permite construir una representaci√≥n profunda del lenguaje humano. Por eso, durante su etapa de entrenamiento (fundamental en la construcci√≥n de la IA generativa) los modelos ajustan sus par√°metros (una especie de ‚Äúperillas‚Äù virtuales) para minimizar los errores de predicci√≥n. As√≠ logran captar relaciones complejas, met√°foras, iron√≠as y dependencias entre conceptos, aunque sin poseer conciencia ni entendimiento real; es decir, no piensan como un humano [(Mitchell 2025a, 2025b)]. Esa ilusi√≥n de ‚Äúchispas de razonamiento‚Äù es, en parte, lo que alimenta el furor actual en torno a estas tecnolog√≠as.

## 1.1 ¬øC√≥mo se construyen la IA generativa?

La construcci√≥n de la IA generativa (por ejemplo, los LLM) se divide en dos grandes etapas: entrenamiento y postentrenamiento [(Karpathy 2025; Raschka 2024a)](https://www.zotero.org/google-docs/?T3tZR2). En la primera, el modelo se alimenta de enormes cantidades de texto (libros, art√≠culos, foros, sitios web) para aprender las estructuras b√°sicas del lenguaje: gram√°tica, vocabulario y relaciones entre palabras. Y se le pide la tarea aparentemente trivial pero fundamental: adivinar cu√°l es la siguiente palabra en una oraci√≥n. El resultado es un modelo base capaz de producir texto (es decir, recitar ‚Äútodo‚Äù el internet) pero a√∫n sin ‚Äúcomportarse‚Äù como un asistente conversacional. Por eso se realiza una segunda etapa, el postentrenamiento, que comienza con el ajuste fino supervisado (SFT). Aqu√≠, el modelo se entrena con conjuntos de datos m√°s peque√±os pero de alta calidad (conversaciones cuidadosamente dise√±adas), donde miles de etiquetadores humanos (o la misma IA generativa) crean pares de pregunta‚Äìrespuesta siguiendo instrucciones detalladas. Por ejemplo [(Penedo et¬†al. 2024)](https://www.zotero.org/google-docs/?HDcv4U):

> Pregunta: ¬øEn qu√© se diferencia el trastorno bipolar de la depresi√≥n unipolar o la depresi√≥n com√∫n?¬†

> Respuesta: Tanto el trastorno bipolar como la depresi√≥n mayor suelen estar asociados a episodios depresivos. Por lo tanto, ambas enfermedades se acompa√±an de depresi√≥n. La diferencia radica en que en el trastorno bipolar las personas tambi√©n presentan per√≠odos de euforia o irritabilidad severa. A estos los llamamos episodios man√≠acos o hipoman√≠acos.¬†

De este modo, el modelo aprende no solo a generar texto, sino a comportarse como un asistente conversacional coherente al refinar el modelo base para seguir reglas conversacionales, sociales y ling√º√≠sticas aprendidas de humanos [(Ouyang et¬†al. 2022)](https://www.zotero.org/google-docs/?xYonKw).

Sin embargo, este ajuste fino no se limita a la imitaci√≥n. Suele incorporarse adem√°s el aprendizaje por refuerzo con retroalimentaci√≥n humana (RLHF), donde personas comparan varias respuestas del modelo, por lo que recibe retroalimentaci√≥n sobre cu√°les soluciones funcionan mejor, afinando m√°s la conducta del modelo de la siguiente manera: el modelo generativo produce varias respuestas a la misma indicaci√≥n (o prompt), personas las ordenan (por ejemplo: ‚Äúmejor, regular, peor‚Äù), y con esas comparaciones se entrena el modelo de recompensa (Reward Model, RM) para puntuar cada salida seg√∫n qu√© tanto coincide con lo que los humanos preferir√≠an. Despu√©s, el modelo generativo se vuelve a entrenar con aprendizaje por refuerzo para maximizar ese puntaje, en un ciclo an√°logo a ‚Äúprobar-equivocarse-ajustar‚Äù [(Ouyang et¬†al. 2022)](https://www.zotero.org/google-docs/?V5kJPR). A veces, en este proceso, surgen patrones de resoluci√≥n paso a paso (pasos intermedios, revisiones, comparaciones o autocorrecciones) que simulan razonamiento. Esta conducta, llamada chain-of-thought o ‚Äúcadena de pensamiento‚Äù [(Wei et¬†al. 2023)](https://www.zotero.org/google-docs/?jOuBfk), se ha observado con fuerza en modelos recientes como DeepSeek R1 [(Guo et¬†al. 2025)](https://www.zotero.org/google-docs/?JHPVg6), donde el refuerzo favorece secuencias largas y estructuradas que mejoran la precisi√≥n en problemas complejos. El modelo genera m√∫ltiples soluciones a un mismo problema y refuerza aquellas que conducen a buenos resultados.¬†

Una vez construidos los modelos generativos, estos se integran en sistemas, com√∫nmente en chatbots conversacionales capaces de mantener di√°logos, simular procesos de razonamiento, procesar millones de tokens (fragmentos de texto) en segundos y generar textos con un nivel de coherencia que hace apenas unos a√±os resultaba impensable. Sin embargo, detr√°s de esa aparente ‚Äúmagia‚Äù se encuentran la estad√≠stica, las matem√°ticas y la computaci√≥n.

## 1.1 ¬øQu√© es un Sistema de IA Generativa?

Un sistema de IA generativa es una aplicaci√≥n que combina uno o varios modelos generativos con otros componentes de software para ofrecer un servicio √∫til a las personas, como los chatbots conversacionales, asistentes para generaci√≥n de c√≥digos o plataformas de creaci√≥n de im√°genes. Por ejemplo, ChatGPT integra el modelo GPT (actualmente GPT-5) y Gemini emplea modelos como gemini-2.5 pro. Estos sistemas reciben prompt, es decir, una instrucci√≥n o consulta textual y generan respuestas, im√°genes o c√≥digo en funci√≥n de dicha entrada (ver Figura 2).

En el caso de sistemas cerrados como ChatGPT o Gemini, sus modelos funcionan como una caja negra: no se conoce con exactitud qu√© datos fueron utilizados durante el entrenamiento ni los procesos aplicados en el postentrenamiento. Lo √∫nico que se sabe con certeza es que el usuario ingresa un prompt y recibe una respuesta a cambio.

Aunque es posible seleccionar la versi√≥n del modelo o modificar algunas configuraciones, el acceso al interior del modelo es restringido y no est√° disponible para el usuario. Esto ha dado origen a la ingenier√≠a de prompts, que es tanto un arte como una ciencia dedicada a dise√±ar y perfeccionar las instrucciones con el fin de guiar al modelo hacia respuestas precisas y √∫tiles (Boonstra 2025; Federiakin et al. 2024; Giray 2023; Lee et al. 2025; White et al. 2023). Cuanto m√°s claro, contextualizado y espec√≠fico sea el prompt, m√°s acertadas y relevantes ser√°n las respuestas obtenidas (ver Figura 3). En otras palabras, no interactuamos directamente con los modelos en s√≠, sino que aprendemos a comunicarnos eficazmente con ellos desarrollando prompts que hablen su idioma.
Esta aproximaci√≥n es crucial para aprovechar al m√°ximo las capacidades de inteligencia artificial conversacional moderna, donde la clave est√° en la calidad y precisi√≥n de la interacci√≥n a trav√©s del lenguaje.


En esencia, reciben un prompt y devuelven un resultado (ver Figura 2). Para sistemas cerrados como ChatGPT o Gemini, sus modelos son una caja negra, se desconoce exactamente qu√© datos se usaron para el entrenamiento y el postentrenamiento, lo √∫nico que sabemos es que ingresamos un prompt y obtenemos algo a cambio. Si bien se puede elegir la versi√≥n del modelo o cambiar algunas configuraciones, no se puede acceder a su interior. De ah√≠ que tengamos la ingenier√≠a de prompts, el arte (y la ciencia) de dise√±ar y perfeccionar instrucciones para guiar al modelo hacia los resultados deseados [(Boonstra 2025; Federiakin et¬†al. 2024; Giray 2023; Lee et¬†al. 2025; White et¬†al. 2023)](https://www.zotero.org/google-docs/?UPbAQ5). Cuanto m√°s claro, contextual y espec√≠fico sea el prompt, m√°s precisas ser√°n las respuestas (ver Figura 3). En otras palabras, no tocamos los modelos, pero s√≠ aprendemos a hablar su idioma.

Se puede pensar en la ingenier√≠a de prompts como elaborar una receta. As√≠ como un chef combina cuidadosamente ingredientes y pasos para lograr un platillo delicioso, un buen prompt combina contexto, tono, ejemplos y formato para obtener la mejor salida posible del modelo [(Amatriain 2024; Sahoo et¬†al. 2025)](https://www.zotero.org/google-docs/?JUv3yU) (ver Figura 4).


## 1.1 Algunos puntos cr√≠ticos de la IA

Por supuesto, los LLM no son infalibles. Una limitaci√≥n conocida son las ‚Äúalucinaciones‚Äù: respuestas inventadas que suenan plausibles pero son falsas [(Ji et¬†al. 2023)](https://www.zotero.org/google-docs/?Jx3VN6). Esto ocurre porque el modelo, al haber sido entrenado para ‚Äúresponder siempre‚Äù, tiende a completar patrones ling√º√≠sticos incluso cuando no tiene informaci√≥n suficiente. Las empresas han reducido este problema incluyendo ejemplos donde la respuesta correcta es ‚Äúno lo s√©‚Äù y, en versiones m√°s avanzadas, permitiendo que el modelo use herramientas externas (como motores de b√∫squeda o int√©rpretes de c√≥digo) para consultar informaci√≥n o realizar c√°lculos exactos. De esta forma, los modelos modernos combinan memoria interna (informaci√≥n a partir de su entrenamiento) con memoria de trabajo (el contexto o informaci√≥n nueva que se le proporciona) y con acceso a herramientas externas, acerc√°ndose cada vez m√°s a lo que pareciera una inteligencia funcional e h√≠brida.

Todo este proceso de entrenamiento requiere recursos colosales: miles de unidades de procesamiento gr√°fico (GPU) trabajando durante semanas o meses, datasets filtrados y depurados y una ingenier√≠a cuidadosa [(Goodfellow, Bengio, y Courville 2016)](https://www.zotero.org/google-docs/?MvTYzM). Si bien, se ha visto que la curaci√≥n de datos¬† [(Penedo et¬†al. 2024)](https://www.zotero.org/google-docs/?tpoxlc), la cual combina procesos autom√°ticos (deduplicaci√≥n, detecci√≥n de idioma, filtros de calidad/toxicidad) con auditor√≠as y criterios humanos (licencias, sesgos, remociones), eleva de forma notable el rendimiento y responsabilidad de modelos comparables. Igualmente, las decisiones de hardware (aceleradores eficientes, centros de datos con energ√≠a baja en carbono) pueden reducir hasta cierto punto la huella de carbono sin sacrificar desempe√±o [(Patterson et¬†al. 2021)](https://www.zotero.org/google-docs/?w5nWiZ).¬† Si bien el escalamiento de los modelos trae costos energ√©ticos y de carbono, estos deben medirse y transparentarse [(Strubell, Ganesh, y McCallum 2019)](https://www.zotero.org/google-docs/?NemeLu). As√≠ mismo, la IA sin gobernanza puede magnificar sesgos y salidas da√±inas como lenguaje de odio, aumentar la opacidad y concentrar poder; por ello, se recomiendan documentaci√≥n rigurosa de datos y modelos, evaluaciones de riesgo y mecanismos de rendici√≥n de cuentas [(Bender et¬†al. 2021; Bengio et¬†al. 2025)](https://www.zotero.org/google-docs/?ziCl9s). De ah√≠ que sea importante la alfabetizaci√≥n cr√≠tica, para conocer lo que los modelos hacen y no hacen, insistir en mantener humanos en el bucle de su creaci√≥n para verificar, contextualizar y decidir, as√≠ como empoderar a m√°s personas (docentes, estudiantes, periodistas, funcionariado y ciudadan√≠a) para entender y usar la IA con juicio informado y responsable [(Mitchell 2019; Mitchell y Krakauer 2023)](https://www.zotero.org/google-docs/?4Iphgm).

## la democratizaci√≥n de la IA

La democratizaci√≥n de la IA exige, como parte de un conjunto m√°s amplio, cuatro compromisos inmediatos: (1) construir capacidades mediante formaci√≥n que permita usar de manera cr√≠tica la IA (alfabetizaci√≥n algor√≠tmica para docentes, estudiantes, investigadores, ONG, pymes y periodistas) de modo que distintos p√∫blicos eval√∫en limitaciones, riesgos y calidad de las salidas [(Bender et¬†al. 2021)](https://www.zotero.org/google-docs/?X2I18g); (2) abrir la participaci√≥n y la gobernanza con consultas p√∫blicas, auditor√≠as y evaluaciones de impacto que obliguen a los sistemas a rendir cuentas ante quienes afectan [(Benajmin 2019)](https://www.zotero.org/google-docs/?9VOENV); (3) promover la apertura del conocimiento como punto de partida (alineada con los principios de ciencia abierta), favoreciendo el acceso universal a publicaciones, datos, documentaci√≥n y artifacts t√©cnicos (cuando sea legal y seguro), as√≠ como la reproducibilidad y la trazabilidad de decisiones [(Kramer y Bosman 2016; Leonelli y Tempini 2020; McKiernan et¬†al. 2016)](https://www.zotero.org/google-docs/?XcNeE4) (McKiernan et al., 2016; Leonelli & Tempini, 2020; Kramer & Bosman, 2018); y (4) desarrollar tecnolog√≠a propia de IA (potenciar infraestructura y talento locales, promover open source y est√°ndares abiertos, cultivar datos y modelos en dominios relevantes (educaci√≥n, salud, comunicaci√≥n), y articular colaboraci√≥n entre academia, ciudadan√≠a y peque√±as empresas para reducir dependencia, fortalecer la innovaci√≥n y asegurar pertinencia contextual [(Birhane 2020; Scao et¬†al. 2023)](https://www.zotero.org/google-docs/?glT0o1).

## 1.1 El Ascenso de la IA de Generativa

Las capacidades de la [[09-Glosario#IA Generativa|IA Generativa]], han avanzado de forma sorprendente durante los √∫ltimos a√±os y han mostrado progresos particularmente notables. En diversas pruebas de referencia estandarizadas (_benchmarks_), las cuales consisten en una serie de acertijos acad√©micos o desaf√≠os de ingenier√≠a de software, los modelos actuales de IA generativa ya logran resolver una gran proporci√≥n de los problemas presentados (ver [[#^fig1|Figura 1]]), alcanzando m√°s del 80% en algunos casos recientes [[08-Referencias#(Maslej et al., 2025|(Maslej et al., 2025)]].

<div align="center">
<img src="Benchmarks.png" style="width:80%">
</div>
 **Figura 1.** Descripci√≥n detallada de la imagen
^fig1



Adem√°s, en pruebas aplicadas en diferentes √°reas como el procesamiento del lenguaje natural, la visi√≥n por computadora, el reconocimiento de voz y las matem√°ticas, han alcanzado e incluso superado el desempe√±o humano. Por ejemplo, apenas unas semanas atr√°s, los modelos m√°s avanzados obtuvieron un rendimiento de medalla de oro en la Olimpiada Internacional de Matem√°ticas 2025 [[08-Referencias#(Maslej et al., 2025|(Maslej et al., 2025)]].

> [!WARNING] Cautela en las Comparaciones 
> Como ha se√±alado el matem√°tico Terence Tao, esto debe manejarse con cautela, ya que sin una metodolog√≠a de evaluaci√≥n controlada y previa para ambos bandos, hay que desconfiar de las comparaciones simplistas entre el desempe√±o de los modelos de IA en competiciones como la IMO y el de los concursantes humanos, pues los sistemas pueden beneficiarse de recursos (m√°s tiempo de c√≥mputo, reformulaci√≥n de enunciados, selecci√≥n de las mejores salidas, etc.) que no est√°n disponibles para los estudiantes [[08-Referencias#(Tao, 2025)|(Tao, 2025)]].

### ¬øPor qu√© este progreso acelerado?

Estas mejoras tienen principalmente dos razones fundamentales:

**1. Escalamiento:** Ahora se usan computadoras mucho m√°s potentes y se le proporciona mucha m√°s informaci√≥n para aprender. Es como si se le diera un "cerebro m√°s grande" y m√°s libros (m√°s im√°genes, audios o videos) para estudiar. Este fen√≥meno de _scaling_ ha demostrado que simplemente aumentar los recursos computacionales y los datos de entrenamiento produce mejoras consistentes en el desempe√±o.

**2. Mejores M√©todos de Razonamiento:** Se han desarrollado t√©cnicas m√°s sofisticadas para resolver problemas complejos:

- **Cadena de pensamiento (_[[09-Glosario#Cadena de Pensamiento|Chain of Thought]]_)**: La IA puede ahora dividir un desaf√≠o complejo en peque√±os pasos, pensando cuidadosamente uno por uno antes de responder. Es como cuando resuelves un problema de matem√°ticas paso a paso, "pensando en voz alta" y mostrando tu razonamiento gradualmente.
- **Aprendizaje por refuerzo**: Mediante un m√©todo similar al ensayo y error, el modelo prueba diferentes soluciones (a veces muy detalladas) y aprende a preferir aquellas que conducen a respuestas correctas.

### Capacidades Sorprendentes en 2025

Gracias a estos avances t√©cnicos, la IA de prop√≥sito general puede hacer cosas que hasta hace poco parec√≠an de ciencia ficci√≥n. Hace cinco a√±os, los principales modelos de IA de prop√≥sito general rara vez pod√≠an producir un p√°rrafo coherente de texto. Hoy podemos:

- Mantener **conversaciones naturales** con ella
- Pedirle que escriba **programas de ingenier√≠a de software** de tama√±o peque√±o a mediano
- Solicitar **traducciones precisas** entre varios idiomas
- Resolver **problemas de libros de texto** de matem√°ticas y ciencias a nivel de posgrado
- Encontrar y **resumir informaci√≥n relevante** en documentos extensos
- **Generar im√°genes** a partir de texto que son dif√≠ciles de distinguir de fotograf√≠as reales
- **Generar v√≠deos** cortos
- **Describir o transcribir** lo que observa en fotos o videos
- Trabajar **simult√°neamente con m√∫ltiples entradas**: texto, im√°genes, audio y video

> [!SUCCESS] Adopci√≥n Masiva 
> El impacto y la rapidez con que estas herramientas han llegado al p√∫blico son notables. Un ejemplo es ChatGPT de OpenAI: tras su lanzamiento a finales de 2022, consigui√≥ m√°s de un mill√≥n de usuarios en apenas cinco d√≠as y alcanz√≥ los 100 millones en solo dos meses. Esto lo convierte en una de las tecnolog√≠as que m√°s r√°pido se ha adoptado en la historia.

Esta nueva y sorprendente versatilidad ha provocado que la IA se integre r√°pidamente en nuestra vida diaria. La encontramos potenciando herramientas que usamos constantemente: desde los motores de b√∫squeda de Google [[08-Referencias#(Reid, 2024)|(Reid, 2024)]] y Microsoft [[08-Referencias#(The Bing Team, 2025)|(The Bing Team, 2025)]] hasta software creativo como Adobe Creative Cloud (Photoshop, Illustrator, Express) [[08-Referencias#(Adobe, 2024)|(Adobe, 2024)]], pasando por plataformas de asistencia legal y sistemas que ayudan a los m√©dicos a tomar decisiones.

Mirando hacia adelante, el potencial es a√∫n mayor. Entre las perspectivas m√°s prometedoras se encuentra su aplicaci√≥n para revolucionar la educaci√≥n haci√©ndola m√°s personalizada, para transformar la medicina con diagn√≥sticos m√°s precisos y el descubrimiento acelerado de f√°rmacos, y para impulsar la investigaci√≥n cient√≠fica en √°reas como la qu√≠mica, biolog√≠a y f√≠sica.

---

## 1.2 ¬øQu√© es la IA Generativa y los Grandes Modelos de Lenguaje?

La **IA generativa** se refiere a sistemas de inteligencia artificial capaces de _generar contenido nuevo_ (texto, im√°genes, audio, c√≥digo, etc.) a partir de patrones aprendidos, en lugar de solo realizar tareas de clasificaci√≥n o predicci√≥n. Un caso particular y fascinante son los **[[09-Glosario#Grandes Modelos de Lenguaje|Grandes Modelos de Lenguaje]]** ([[09-Glosario#LLM|LLM]], por sus siglas en ingl√©s), que son modelos de _aprendizaje profundo_ de gran escala entrenados con enormes cantidades de texto para producir lenguaje natural coherente [[08-Referencias#(Amazon Web Services, s. f.)|(Amazon Web Services, s. f.)]].

```mermaid
graph LR
    A[IA Generativa] --> B[Texto: LLMs]
    A --> C[Im√°genes: DALL-E, Midjourney]
    A --> D[Audio: M√∫sica, Voz]
    A --> E[Video: Generaci√≥n de clips]
    A --> F[C√≥digo: Copilot, CodeLlama]
    
    style B fill:#4A90E2
    style A fill:#E8F4F8
```

Estos modelos pueden responder preguntas, mantener conversaciones, traducir, programar y mucho m√°s, adapt√°ndose a multitud de tareas sin reentrenamiento espec√≠fico. En esencia, un LLM aprende la probabilidad de continuaci√≥n de secuencias de texto: **genera palabra por palabra (en realidad, _[[09-Glosario#Tokens|token]]_ por token) el contenido m√°s probable** dado un contexto previo.

### La Arquitectura Transformer: El Motor de los LLMs

Gracias a arquitecturas modernas, especialmente los _[[09-Glosario#Transformers|Transformers]]_, los LLM aprenden las relaciones entre palabras y conceptos en el lenguaje de forma no secuencial sino _paralela_, capturando dependencias de largo alcance en un texto [[08-Referencias#(Amazon Web Services, s. f.)|(Amazon Web Services, s. f.)]]. Esto les permite _entender el contexto global_ de una entrada y producir respuestas m√°s coherentes.

> [!TIP]+ Pre-entrenamiento y Ajuste Fino
> La mayor√≠a de LLM actuales son **modelos generativos pre-entrenados** (_Generative Pre-trained Transformers_, de ah√≠ nombres como GPT):
>
> 1. **[[09-Glosario#Pre-entrenamiento|Pre-entrenamiento]]**: Se entrenan en un corpus gigantesco de texto mediante aprendizaje autosupervisado (prediciendo la siguiente palabra)
> 2. **[[09-Glosario#Ajuste fino|Ajuste fino]]** (_fine-tuning_): Se refinan con t√©cnicas adicionales para tareas concretas o para seguir instrucciones humanas (p.ej. afinaci√≥n con refuerzo y feedback humano, _[[09-Glosario#RLHF|RLHF]]_)

Un aspecto clave es que los LLM son extremadamente flexibles: con _las mismas neuronas_ pueden redactar un ensayo, escribir c√≥digo o responder una pregunta factual simplemente cambiando la _instrucci√≥n o prompt_ que reciben. Esto representa un cambio de paradigma frente a modelos m√°s peque√±os o espec√≠ficos, y ha potenciado aplicaciones como asistentes virtuales avanzados, herramientas de resumen autom√°tico y generadores de c√≥digo natural [[08-Referencias#(Amazon Web Services, s. f.)|(Amazon Web Services, s. f.)]].

> [!WARNING] Limitaciones Importantes
> Los LLM tambi√©n presentan limitaciones significativas:
>
> - No siempre "entienden" como un humano
> - Pueden generar informaci√≥n incorrecta (fen√≥meno de _[[09-Glosario#Alucinaciones|alucinaci√≥n]]_)
> - Su rendimiento depende de la calidad y amplitud de su entrenamiento
> - Pueden reproducir sesgos presentes en sus datos de entrenamiento

---

## 1.3 Conceptos Indispensables: Tokens, Ventana de Contexto y Memoria del Modelo

Para comprender el funcionamiento de los LLM y c√≥mo interactuamos con ellos, debemos conocer conceptos fundamentales que a menudo se comparan con la **memoria humana**: la _memoria de trabajo_ (de corto plazo) del modelo versus la _memoria de entrenamiento_ (conocimiento de largo plazo). Estas nociones se materializan en la **[[09-Glosario#Ventana de Contexto|ventana de contexto]]** y los **par√°metros entrenados** del modelo, respectivamente.

### 1.3.1 Tokens: La Unidad B√°sica de Procesamiento

Los LLM no leen palabras individualmente sino que las descomponen en piezas m√°s peque√±as llamadas **_[[09-Glosario#Tokens|tokens]]_**. Un token puede ser una palabra entera, un fragmento de palabra o un s√≠mbolo de puntuaci√≥n.

> [!EXAMPLE]+ Ejemplo de Tokenizaci√≥n 
> La frase _"¬øC√≥mo est√°s?"_ en espa√±ol puede descomponerse en 5 tokens [[08-Referencias#(Robles, 2025)|(Robles, 2025)]]:
> 
> - `¬ø`
> - `C√≥mo`
> - `est`
> - `√°s`
> - `?`

Cada modelo tiene su forma de tokenizar el texto (OpenAI, Google, Meta, etc., usan algoritmos de tokenizaci√≥n distintos), pero en promedio **1 token equivale a aproximadamente 3-4 caracteres** (aunque var√≠a seg√∫n el idioma; en ingl√©s ~0.75 palabras por token, en espa√±ol un token suele representar algo menos que una palabra entera) [[08-Referencias#(Robles, 2025)|(Robles, 2025)]].

```mermaid
graph TD
    A[Texto: ¬øC√≥mo est√°s?] --> B[Tokenizaci√≥n]
    B --> C[Token 1: ¬ø]
    B --> D[Token 2: C√≥mo]
    B --> E[Token 3: est]
    B --> F[Token 4: √°s]
    B --> G[Token 5: ?]
    
    style A fill:#E8F4F8
    style B fill:#4A90E2,color:#fff
    style C fill:#98D8C8
    style D fill:#98D8C8
    style E fill:#98D8C8
    style F fill:#98D8C8
    style G fill:#98D8C8
```

Esto es importante porque tanto la entrada que proporcionamos al modelo como la salida que genera se miden en n√∫mero de tokens.

### 1.3.2 Ventana de Contexto: La Memoria de Trabajo

La **ventana de contexto** es la cantidad m√°xima de tokens que el modelo puede "tener en mente" o procesar a la vez en una interacci√≥n. Es an√°loga a la **memoria de corto plazo** humana: limita cu√°nta informaci√≥n previa el modelo puede recordar durante la generaci√≥n de una respuesta [[08-Referencias#(Robles, 2025)|(Robles, 2025)]].

> [!INFO]- ¬øQu√© Incluye la Ventana de Contexto? 
> En aplicaciones conversacionales, la ventana de contexto incluye:
> 
> - **Instrucciones del sistema**: Prompts ocultos que gu√≠an estilo y comportamiento
> - **Historial de la conversaci√≥n**: Todos los mensajes previos recientes
> - **Datos recuperados**: De bases de conocimiento (en enfoques RAG)
> - **Tu pregunta actual**: El nuevo mensaje del usuario
> - **La respuesta generada**: Los tokens que el modelo produce
> - **Marcas especiales de formato**: Delimitadores y metadatos
> 
> Todos estos elementos compiten por espacio en la ventana de contexto finita [[08-Referencias#(Robles, 2025)|(Robles, 2025)]].

Por ejemplo, un modelo con ventana de 4,000 tokens puede considerar unos 4K tokens combinando la pregunta del usuario y la respuesta que genere. Si se excede ese l√≠mite, el modelo no procesar√° el texto adicional (o lo truncar√°), resultando en p√©rdidas de informaci√≥n.

> [!EXAMPLE] Ejemplo Pr√°ctico 
> Esto explica por qu√© no podemos simplemente darle _el texto completo de "Don Quijote" a ChatGPT-3.5_ (con ~4K tokens de contexto) y pedir un resumen ‚Äî **superar√≠a su ventana y no podr√≠a ni leerlo** [[08-Referencias#(Codificando Bits, 2023)|(Codificando Bits, 2023)]].

Ha surgido la **ingenier√≠a de contexto** como disciplina: decidir estrat√©gicamente qu√© informaci√≥n incluir o resumir en el prompt para aprovechar al m√°ximo la ventana limitada.

### 1.3.3 Memoria de Entrenamiento: El Conocimiento a Largo Plazo

A diferencia de la memoria de trabajo acotada por la ventana de contexto, un LLM posee una suerte de _memoria impl√≠cita de largo plazo_ en sus **par√°metros entrenados**. Durante el pre-entrenamiento, el modelo ajust√≥ miles de millones (hasta _cientos de miles de millones_ en los LLM m√°s grandes) de par√°metros para absorber patrones del lenguaje y hechos del mundo a partir de textos masivos (libros, art√≠culos, p√°ginas web, c√≥digo, etc.).

Esto significa que _gran parte del conocimiento est√° almacenado en el modelo_ tras el entrenamiento, an√°logo a conocimientos que un humano almacena en su memoria a largo plazo. Por ejemplo, GPT-3 se entren√≥ con ~45 terabytes de texto y alcanz√≥ 175 mil millones de par√°metros, incorporando as√≠ enormes cantidades de informaci√≥n general (datos hasta ~2021) en sus "pesos" [[08-Referencias#(Amazon Web Services, s. f.)|(Amazon Web Services, s. f.)]].

```mermaid
graph TB
    A[Modelo de Lenguaje] --> B[Ventana de Contexto<br/>Memoria de Trabajo]
    A --> C[Par√°metros Entrenados<br/>Memoria de Largo Plazo]
    
    B --> D[Limitada: 4K - 2M tokens]
    B --> E[Informaci√≥n actual<br/>de la conversaci√≥n]
    B --> F[Se resetea cada sesi√≥n]
    
    C --> G[Masiva: Billones de par√°metros]
    C --> H[Conocimiento general<br/>hasta fecha de corte]
    C --> I[Permanente pero imperfecta]
    
    style A fill:#4A90E2,color:#fff
    style B fill:#98D8C8
    style C fill:#F5A623
    style D fill:#E8F4F8
    style E fill:#E8F4F8
    style F fill:#E8F4F8
    style G fill:#FEF5E7
    style H fill:#FEF5E7
    style I fill:#FEF5E7
```

> [!WARNING]+ No es una memoria perfecta 
> Esta memoria de entrenamiento **no es perfecta ni organizada**:
> 
> - Los LLM no recuerdan datos concretos como una base de datos
> - Generan respuestas basadas en patrones estad√≠sticos
> - A veces "recuerdan" con exactitud sorprendente (definiciones, c√≥digo conocido, citas)
> - Otras veces confabulan detalles incorrectos si no "memorizaron" ese dato con fidelidad

Investigaciones muestran que los transformadores pueden llegar a memorizar trozos exactos de sus datos de entrenamiento, especialmente aquellos √∫nicos o repetitivos [[08-Referencias#(Zia, 2025)|(Zia, 2025)]]. Esto plantea riesgos: **un modelo puede sin querer revelar informaci√≥n sensible** presente en sus datos de entrenamiento (p. ej., fragmentos de c√≥digo propietario o informaci√≥n personal) si se le induce correctamente [[08-Referencias#(Zia, 2025)|(Zia, 2025)]].

> [!TIP] Diferencia Clave 
> **Ventana de contexto** = Lo que el modelo puede ver y recordar _en este instante_  
> **Conocimiento entrenado** = Todo lo que _"ha aprendido" antes_ (hasta su fecha de corte de entrenamiento)

### ¬øPor qu√© importan tanto estos l√≠mites?

Porque determinan _lo que el modelo puede y no puede hacer_ con la informaci√≥n:

- Si nuestra pregunta requiere m√°s contexto del que cabe en su ventana, tendremos que **resumir o partir la tarea**
- Si preguntamos sobre hechos posteriores a la fecha de entrenamiento, el modelo posiblemente **no lo sepa** a menos que se lo proporcionemos en el prompt
- Muchos sistemas actuales **combinan LLMs con herramientas externas** (b√∫squedas en internet, bases de conocimiento actualizadas) para recuperar datos frescos

---

## 1.4 Funcionamiento General de los LLM: De la Entrada a la Salida

¬øC√≥mo logra un LLM producir una respuesta coherente a una pregunta? Comprender este proceso nos ayuda a formular mejores prompts y entender sus limitaciones.

```mermaid
flowchart TD
    A[Entrada del Usuario] --> B[1- Tokenizaci√≥n]
    B --> C[2- Embeddings<br/>Representaciones vectoriales]
    C --> D[3- Procesamiento Transformer<br/>Auto-atenci√≥n en m√∫ltiples capas]
    D --> E[4- Generaci√≥n Token por Token]
    E --> F{¬øCompletado?}
    F -->|No| G[Agregar token al contexto]
    G --> E
    F -->|S√≠| H[Respuesta Final]
    
    style A fill:#E8F4F8
    style B fill:#98D8C8
    style C fill:#98D8C8
    style D fill:#4A90E2,color:#fff
    style E fill:#F5A623
    style H fill:#98D8C8
```

### 1.4.1 Tokenizaci√≥n de la Entrada

El texto de entrada (prompt del usuario + contexto adicional como instrucciones del sistema o historial) se convierte en tokens num√©ricos. Gracias a las _incrustaciones_ ([[09-Glosario#Embeddings|embeddings]]), el modelo representa cada token como un vector en un espacio matem√°tico, de forma que tokens con significados relacionados quedan cercanos en ese espacio [[08-Referencias#(Amazon Web Services, s. f.)|(Amazon Web Services, s. f.)]]. Esto permite captar similitudes sem√°nticas m√°s all√° de coincidencias exactas de palabras.

### 1.4.2 Procesamiento mediante la Arquitectura Transformer

Los _Transformers_ revolucionaron los modelos de lenguaje al introducir el mecanismo de **auto-atenci√≥n**. En cada capa del modelo, cada token "presta atenci√≥n" a todos los dem√°s tokens en la secuencia para calcular qu√© tan relevantes son entre s√≠.

> [!EXAMPLE] Auto-atenci√≥n en Acci√≥n 
> En la frase "El perro persigue al gato porque **es** travieso", la auto-atenci√≥n adecuada ayuda a inferir que "es" se refiere al gato y no al perro.

Al procesar los tokens en _paralelo_ y con m√∫ltiples _cabezas de atenci√≥n_, el modelo construye representaciones internas ricas en contexto para cada posici√≥n de la secuencia. El gran tama√±o (muchas capas, muchas neuronas) le da capacidad de expresar funciones complejas del lenguaje.

### 1.4.3 Generaci√≥n Token por Token

Una vez procesada la entrada, el modelo produce un token de salida a la vez (cada nuevo token se incorpora al contexto y el proceso se repite). En cada paso escoge el token m√°s probable seg√∫n la distribuci√≥n aprendida, **aunque a menudo se introduce aleatoriedad controlada** (temperatura, top-k, etc.) para que las respuestas no sean siempre mec√°nicamente iguales. Este proceso contin√∫a hasta completar la respuesta o alcanzar el l√≠mite de la ventana de contexto.

> [!INFO] Importante Destacar 
> El modelo _no "entiende" en el sentido humano_, sino que sigue patrones estad√≠sticos. Sin embargo, la inmensa cantidad de datos y par√°metros le permiten _aproximar comprensi√≥n_ de manera funcional. Por ejemplo, un LLM puede traducir de un idioma a otro no porque sepa reglas gramaticales expl√≠citamente, sino porque ha inferido un inmenso mapa de correspondencias y usos del lenguaje durante su entrenamiento.

### 1.4.4 Ajuste Fino y Alineaci√≥n

Tras el pre-entrenamiento, muchos LLMs pasan por etapas adicionales de refinamiento:

- **Ajuste fino instructivo**: Se alimentan ejemplos de instrucciones humanas y respuestas deseadas
- **Aprendizaje por refuerzo con feedback humano (RLHF)**: Evaluadores humanos gu√≠an el modelo para que sus respuestas sean √∫tiles y seguras

Esto los convierte en asistentes m√°s alineados a lo que espera un usuario t√≠pico al interactuar (por ejemplo, rechazar solicitudes inapropiadas, seguir el tono pedido, etc.). Aun con estas t√©cnicas, los modelos pueden producir sesgos o contenidos objetables, lo que subraya que _siguen sin comprender plenamente las implicaciones de sus respuestas_ ‚Äì simplemente han ajustado sus probabilidades de salida.

---

## 1.5 Evoluci√≥n Reciente de los LLM: Modelos Destacados y Sus Capacidades en 2025

El campo de los LLM avanza r√°pidamente. A continuaci√≥n, presentamos una **comparativa funcional** de algunos de los modelos generativos m√°s recientes (2024-2025) y l√≠deres del mercado. El objetivo no es ser exhaustivo con cada detalle t√©cnico, sino dar un panorama de _hasta d√≥nde han llegado_ estos modelos en t√©rminos de capacidad, tama√±o, ventana de contexto y enfoques diferenciadores.

### 1.5.1 GPT-5 (OpenAI)

Lanzado por OpenAI en agosto de 2025, GPT-5 se presenta como _su modelo de lenguaje unificado m√°s avanzado hasta la fecha_ [[08-Referencias#(OpenAI, 2025)|(OpenAI, 2025)]].

**Caracter√≠sticas Principales:**

- **Razonamiento Modular**: Integra varios "modos" de razonamiento en un solo sistema, con un enrutador inteligente que decide si una consulta se responde de forma r√°pida con un sub-modelo eficiente o si activa un modo de _pensamiento profundo_ para preguntas complejas [[08-Referencias#(OpenAI, 2025)|(OpenAI, 2025)]].
    
- **Variantes Disponibles**:
    
    - **GPT-5 est√°ndar**: Para uso general
    - **GPT-5 Pro**: Para suscriptores, con capacidades de razonamiento extendido m√°s potentes
    - **GPT-5-mini y GPT-5-nano**: Para diferentes velocidades/costos [[08-Referencias#(Kargwal, 2025)|(Kargwal, 2025)]]
- **[[09-Glosario#Multimodalidad|Multimodalidad]] Nativa**: Habilidades de visi√≥n y voz integradas. Puede analizar im√°genes, diagramas, reconocer comandos de voz o generar respuestas habladas.
    

> [!SUCCESS]+ Ventana de Contexto Masiva 
> GPT-5 maneja hasta **~400,000 tokens de contexto** en ciertas configuraciones [[08-Referencias#(Cogni Down Under, 2025)|(Cogni Down Under, 2025)]], equivalente a cientos de p√°ginas de texto. Esto representa un salto enorme respecto a GPT-4 (8K-32K) y GPT-3.5 (4K).

**Mejoras en Fiabilidad:**

- Reducci√≥n significativa de alucinaciones
- Mayor fidelidad al seguir instrucciones
- Mejor desempe√±o en programaci√≥n, matem√°ticas avanzadas y redacci√≥n creativa [[08-Referencias#(OpenAI, 2025)|(OpenAI, 2025)]]

**Conocimiento actualizado hasta**: Finales de 2024

### 1.5.2 Claude 4.5 (Anthropic)

Claude es la familia de modelos desarrollada por Anthropic, un laboratorio enfocado en IA responsable. **Claude 4.5** (nombre c√≥digo _Claude Sonnet 4.5_) se posiciona como **el modelo puntero orientado a tareas complejas de razonamiento y coding** [[08-Referencias#(Anthropic, 2025)|(Anthropic, 2025)]].

**Caracter√≠sticas Principales:**

- **Excelencia en Codificaci√≥n**: Anthropic lo describe como "el mejor modelo de codificaci√≥n del mundo" en su lanzamiento, destacando su capacidad para manejar proyectos de programaci√≥n de larga duraci√≥n con m√≠nima intervenci√≥n humana [[08-Referencias#(Anthropic, 2025)|(Anthropic, 2025)]].
    
- **Agente Aut√≥nomo**: Especialmente bueno planificando y ejecutando secuencias de acciones (navegar herramientas, escribir y depurar c√≥digo, manejar m√∫ltiples pasos en tareas de investigaci√≥n) manteniendo contexto en horizontes amplios.
    
- **Enfoque en Seguridad**: Incorpora mejoras para evitar respuestas t√≥xicas o no √©ticas, siendo su modelo "m√°s alineado" hasta la fecha [[08-Referencias#(Anthropic, 2025)|(Anthropic, 2025)]].
    

**Ventana de Contexto:**

- **Oficial**: 200,000 tokens (equivalente a ~150,000 palabras)
- **Experimental**: Hasta 1 mill√≥n de tokens en entornos empresariales selectos [[08-Referencias#(Cogni Down Under, 2025)|(Cogni Down Under, 2025)]]

**Variantes Disponibles:**

|Variante|Prop√≥sito|Caracter√≠sticas|
|---|---|---|
|**Claude Sonnet 4.5**|Razonamiento intenso|Versi√≥n completa, ideal para tareas complejas|
|**Claude Haiku 4.5**|Velocidad y costo|Optimizada para respuesta en tiempo real, ofrecida gratuitamente por tiempo limitado [[08-Referencias#(Nu√±ez, 2025)|

> [!TIP] Fortaleza Principal 
> Claude 4.5 se destaca por **fiabilidad en tareas de larga duraci√≥n, seguridad en las respuestas y manejo de contextos masivos**. Ha liderado el ranking **SWE-bench** de tareas de programaci√≥n de extremo a extremo [[08-Referencias#(Anthropic, 2025)|(Anthropic, 2025)]].

**Multimodalidad**: Soporte visual b√°sico (procesamiento de im√°genes para asistir en programaci√≥n visual o lectura de documentos escaneados), pero su fortaleza principal sigue siendo texto y c√≥digo.

### 1.5.3 Gemini 2.5 (Google DeepMind)

Google, tras fusionar su equipo de investigaci√≥n Brain con DeepMind, introdujo la saga de modelos **Gemini**. **Gemini 2.5**, lanzado a inicios-mediados de 2025, se posiciona como _el modelo m√°s inteligente de Google hasta la fecha_ [[08-Referencias#(Google, 2025)|(Google, 2025)]].

**Caracter√≠sticas Principales:**

- **Modelos con Pensamiento**: Incorpora de forma nativa t√©cnicas de _chain-of-thought_. Gemini 2.5 puede "pensar" varios pasos internamente antes de dar una respuesta, emulando un razonamiento deliberativo [[08-Referencias#(Google, 2025)|(Google, 2025)]].

**Variantes Disponibles:**

|Variante|Capacidad|Ventana de Contexto|
|---|---|---|
|**Gemini 2.5 Pro**|M√°xima, para tareas complejas|1,000,000 tokens (planea extender a 2M)|
|**Gemini 2.5 Flash**|Optimizada para rapidez y escala|-|

> [!SUCCESS]+ Ventana de Contexto R√©cord 
> Gemini 2.5 Pro soporta hasta **1,000,000 de tokens de contexto**, equivalente a aproximadamente **1,500 p√°ginas de texto o 30,000 l√≠neas de c√≥digo** [[08-Referencias#(Google, 2025)|(Google, 2025)]]. Google planea extenderla a _2 millones_ en futuras actualizaciones [[08-Referencias#(Google, 2025)|(Google, 2025)]].

**Multimodalidad Completa**: Gemini es nativamente multimodal, aceptando _texto, im√°genes, audio e incluso video como entrada_. Puede analizar el contenido de una imagen, transcribir y analizar un audio, o describir un video corto en la misma sesi√≥n.

**Seguridad**: Incorpora avanzadas protecciones contra _prompt injections_ y contenido malicioso, apuntando al uso empresarial seguro [[08-Referencias#(Google, 2025)|(Google, 2025)]].

**Acceso**: Disponible a trav√©s de **Vertex AI** en Google Cloud y **Google AI Studio** para investigadores.

> [!WARNING] Desaf√≠os de Contexto Extremo 
> A pesar de su gran contexto, manejar coherencia en 1M de tokens es desafiante y a veces "olvida" partes remotas del contexto [[08-Referencias#(Cogni Down Under, 2025)|(Cogni Down Under, 2025)]].

### 1.5.4 Otros Modelos y Panorama General

El ecosistema de LLM en 2025 incluye otros actores notables que ampl√≠an las opciones disponibles para investigadores:

**LLaMA 2 y el Ecosistema Open Source (Meta)**

Meta abri√≥ en 2023 la puerta de los _LLM de c√≥digo abierto_ con **LLaMA 2**, un modelo de hasta 70 mil millones de par√°metros disponible para uso tanto investigador como comercial [[08-Referencias#(Bergmann, 2023)|(Bergmann, 2023)]]. Caracter√≠sticas:

- Ventana de contexto: 4K tokens (doble que LLaMA 1)
- Demostr√≥ que comunidades abiertas pueden afinar y mejorar modelos sustanciales
- Inspir√≥ multitud de variantes open-source: Mistral 7B, Falcon, etc.

**Otros Jugadores Emergentes:**

- **xAI Grok**: Conectado en tiempo real a la web para respuestas con informaci√≥n actualizada
- **Amazon Bedrock**: Plataforma que ofrece acceso a Claude, Titan (propio de AWS) y otros modelos
- **DeepSeek**: Modelos open-source con enfoque en eficiencia

```mermaid
graph TB
    A[Modelos LLM 2025] --> B[Propietarios<br/>Premium]
    A --> C[Open Source<br/>Comunidad]
    
    B --> D[GPT-5<br/>OpenAI]
    B --> E[Claude 4.5<br/>Anthropic]
    B --> F[Gemini 2.5<br/>Google]
    
    C --> G[LLaMA 2<br/>Meta]
    C --> H[Mistral<br/>7B-8x22B]
    C --> I[Falcon<br/>UAE]
    
    style A fill:#4A90E2,color:#fff
    style B fill:#F5A623
    style C fill:#98D8C8
```

> [!INFO]+ Tama√±os y Eficiencia 
> En cuanto a _par√°metros_, los tama√±os siguen en aumento pero con matices:
> 
> - GPT-5 se rumorea que puede tener del orden del trill√≥n de par√°metros (no confirmado)
> - Claude 4.5 no revel√≥ su tama√±o exacto, se asume en cientos de miles de millones
> - Gemini 2.5 Pro est√° en la liga de los cientos de miles de millones
> 
> Sin embargo, la eficacia no es solo cuesti√≥n de cantidad de par√°metros, sino de _calidad de entrenamiento_ y _novedades arquitect√≥nicas_. Modelos abiertos m√°s peque√±os (6B-20B par√°metros) finamente ajustados pueden superar a modelos enormes gen√©ricos en tareas particulares.

### 1.5.5 Tabla Comparativa Resumida

| Modelo                | Organizaci√≥n    | Ventana de Contexto        | Fortalezas                                       | Multimodal                         |
| --------------------- | --------------- | -------------------------- | ------------------------------------------------ | ---------------------------------- |
| **GPT-5**             | OpenAI          | ~400K tokens               | Razonamiento modular, reducci√≥n de alucinaciones | ‚úÖ (visi√≥n + voz)                   |
| **Claude 4.5 Sonnet** | Anthropic       | 200K (1M experimental)     | Codificaci√≥n, seguridad, contexto largo          | ‚ö†Ô∏è (b√°sico visual)                 |
| **Gemini 2.5 Pro**    | Google DeepMind | 1M tokens (2M planificado) | Pensamiento estructurado, contexto masivo        | ‚úÖ (texto + imagen + audio + video) |
| **LLaMA 2**           | Meta            | 4K tokens                  | Open source, personalizable                      | ‚ùå                                  |

---

## 1.6 Conclusi√≥n: Fundamentos para la Investigaci√≥n Acad√©mica

Los fundamentos de los LLM abarcan entender c√≥mo manejan contexto y conocimiento, y apreciar las diferencias entre las principales ofertas actuales. Hemos visto que:

1. **Conceptos clave** como la ventana de contexto definen la memoria activa del modelo, mientras que el entrenamiento define su memoria duradera.
    
2. **Modelos l√≠deres** como GPT-5, Claude 4.5 y Gemini 2.5 empujan los l√≠mites en diferentes direcciones:
    - Unificaci√≥n de modos de razonamiento
    - Contextos masivos para procesamiento de documentos extensos
    - Multimodalidad profunda para an√°lisis de diferentes tipos de datos
    - Especializaci√≥n en codificaci√≥n y agentes aut√≥nomos
3. **Limitaciones inherentes**: A pesar de sus impresionantes capacidades, estos modelos a√∫n no "comprenden" como humanos, pueden alucinar informaci√≥n y requieren prompts cuidadosamente dise√±ados.
    

Esta base conceptual nos servir√° para entender _por qu√©_ ciertas t√©cnicas funcionan y _c√≥mo_ sacar el mayor provecho de la IA generativa en nuestros workflows cient√≠ficos. A lo largo de este libro exploraremos:

- **Ingenier√≠a de Prompts** (Cap√≠tulo 2): C√≥mo _formular mejores instrucciones_ para obtener respuestas precisas y relevantes
- **Ingenier√≠a de Contexto** (Cap√≠tulo 3): C√≥mo _estructurar contextos_ y gestionar informaci√≥n dentro de la ventana limitada
- **Herramientas especializadas** (Cap√≠tulos 4-6): C√≥mo combinar modelos con fuentes de informaci√≥n y flujos de trabajo integrados
- **Consideraciones √©ticas** (Cap√≠tulo 7): Una mirada cr√≠tica a las implicaciones del uso de IA en investigaci√≥n

> [!TIP] Pr√≥ximo Paso 
> Ahora que comprendemos los fundamentos t√©cnicos, estamos listos para aprender el arte de comunicarnos eficazmente con estos sistemas. En el siguiente cap√≠tulo abordaremos la **Ingenier√≠a de Prompts**: la habilidad clave para transformar nuestras ideas en resultados precisos mediante instrucciones bien dise√±adas.

---



