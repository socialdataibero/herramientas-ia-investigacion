---
dg-publish: true
date_created: 2025-10-22T02:17:35-06:00
date_modified: 2025-11-04T14:27:53-06:00
dg-path: 01-Fundamentos-IA-Generativa.md
cover: "![[Gemini_Generated_Image_byudq9byudq9byud.png]]"
tags:
  - proyecto-ia
resumen: Define qu√© es la ingenier√≠a de prompts y sus t√©cnicas principales para guiar a los modelos.
icono: üí°
estado: Borrador
---

# Cap√≠tulo 1: Fundamentos de la IA Generativa

Hasta hace pocos a√±os, hablar de inteligencia artificial (IA) era casi sin√≥nimo de ciencia ficci√≥n. Hoy, en cambio, la IA se ha infiltrado en nuestra vida cotidiana: forma parte de nuestras conversaciones, influye en lo que vemos en redes sociales e incluso en los memes que compartimos. ¬øQu√© ha pasado para que "esa cosa de los robots" se haya vuelto tan omnipresente?

Una de las claves est√° en el auge de los modelos generativos, especialmente los modelos de lenguaje de gran tama√±o (Large Language Models, LLM) presentes en chatbots como ChatGPT, DeepSeek, LeChat, entre otros. Estos sistemas son capaces de predecir la siguiente palabra en casi cualquier contexto, generando textos extensos, coherentes y, en muchos casos, indistinguibles de los escritos por personas [[08-Referencias#(Achiam et al., 2024)|(Achiam et al., 2024)]].

Esta capacidad de generar contenido (raz√≥n por la cual tambi√©n se les conoce como IA generativa), les ha permitido tambi√©n resolver una amplia gama de pruebas de referencia estandarizadas [[08-Referencias#(Bengio et al., 2025)|(Bengio et al., 2025)]]; [[08-Referencias#(Maslej, 2025)|(Maslej, 2025)]]. Dichas pruebas consisten en desaf√≠os acad√©micos o t√©cnicos que ponen a prueba habilidades de razonamiento, "comprensi√≥n" y resoluci√≥n de problemas. En algunos casos, estos modelos han alcanzado tasas de √©xito superiores al 80%  y en campos como la visi√≥n por computadora, el reconocimiento de voz, las matem√°ticas o la inform√°tica, su desempe√±o iguala e incluso supera al humano [[08-Referencias#(Bengio et al., 2025)|(Bengio et al., 2025)]]; [[08-Referencias#(Google DeepMind, 2025a)|(Google DeepMind, 2025a)]]; [[08-Referencias#(Google DeepMind, 2025b)|(Google DeepMind, 2025b)]]; [[08-Referencias#(Maslej, 2025)|(Maslej, 2025)]]; [[08-Referencias#(Trinh et al., 2024)|(Trinh et al., 2024)]].

Este avance tecnol√≥gico est√° transformando tambi√©n el √°mbito de la investigaci√≥n acad√©mica. Por lo que, para adentrarnos con confianza en el nuevo panorama de la investigaci√≥n cient√≠fica asistida por IA, es fundamental comprender primero qu√© es esta tecnolog√≠a y c√≥mo funciona. Este cap√≠tulo sienta esas bases conceptuales sin pretender exhaustividad t√©cnica, sino ofrecer un marco claro y pr√°ctico para estudiantes, docentes e investigadores.

## 1.1 ¬øQu√© es la IA Generativa?

La IA generativa es un subcampo de la inteligencia artificial que usa modelos capaces de producir contenido nuevo (texto, im√°genes, audio, video o c√≥digo) a partir de patrones aprendidos en enormes vol√∫menes de datos [[08-Referencias#(Chang et al., 2024)|(Chang et al., 2024)]]; [[08-Referencias#(Raschka, 2024a)|(Raschka, 2024a)]]; [[08-Referencias#(Xiao y Zhu, 2025)|(Xiao y Zhu, 2025)]]. Ese salto fue lo que convirti√≥ a chatbots como ChatGPT, Gemini, Grok, Claude, Meta AI, DeepSeek, Qwen o Le Chat en asistentes vers√°tiles de uso diario.

En etapas anteriores, los chatbots tradicionales se limitaban a respuestas preestablecidas para un n√∫mero reducido de preguntas. De forma similar, el aprendizaje autom√°tico cl√°sico se orientaba a problemas bien delimitados (clasificaci√≥n de im√°genes, detecci√≥n de spam, an√°lisis de sentimiento, etc.), de modo que cada tarea requer√≠a su propio modelo. No obstante, cuando se trataba de tareas ling√º√≠sticas que requer√≠an comprensi√≥n profunda y producci√≥n de texto (por ejemplo, analizar mensajes largos o generar contenidos originales coherentes y pertinentes al contexto) el desempe√±o era limitado. En la actualidad, un solo modelo generativo es capaz de adaptarse a una gran variedad de prop√≥sitos sin requerir entrenamientos espec√≠ficos para cada tarea (por eso tambi√©n se les conoce como modelos multimodales [[08-Referencias#(Alammar y Grootendorst, 2024)|(Alammar y Grootendorst, 2024)]]; [[08-Referencias#(Raschka, 2024b)|(Raschka, 2024b)]]). Por ejemplo; procesan y traducen informaci√≥n, resumen y elaboran explicaciones did√°cticas; reescriben textos, "entienden" y proponen ideas creativas; generan c√≥digo o contenido audiovisual; y describen im√°genes o videos, entre muchas otras funciones. De ah√≠ el entusiasmo de que estamos frente a un nuevo paradigma.

Cuando decimos que un modelo generativo (como es el caso de los LLM) ‚Äúentiende‚Äù o ‚Äúidea‚Äù, no hablamos de conciencia, compresi√≥n o creatividad humana. Hablamos de que procesa y genera texto coherente y √∫til en contexto. A veces parece que ‚Äúrazona‚Äù, pero lo que hay detr√°s es una predicci√≥n de la palabra m√°s probable que sigue a una secuencia anterior. Si escribes ‚ÄúLas quesadillas van con‚Ä¶‚Äù, el modelo calcula estad√≠sticamente cu√°l palabra tiene mayor probabilidad de aparecer despu√©s, por ejemplo, entre las palabras ‚Äúaguacate‚Äù, ‚Äúcebolla‚Äù, ..., o ‚Äúqueso‚Äù, ser√≠a ‚Äúqueso‚Äù la palabra m√°s probable¬† (la que m√°s aparece en los textos utilizados para entrenar el modelo). Esa simple tarea de predicci√≥n, repetida miles de millones de veces, permite construir una representaci√≥n profunda del lenguaje humano. Por eso, durante su etapa de entrenamiento (fundamental en la construcci√≥n de la IA generativa) los modelos ajustan sus par√°metros (una especie de ‚Äúperillas‚Äù virtuales) para minimizar los errores de predicci√≥n. As√≠ logran captar relaciones complejas, met√°foras, iron√≠as y dependencias entre conceptos, aunque sin poseer conciencia ni entendimiento real; es decir, no piensan como un humano [[08-Referencias#(Mitchell, 2025a)|(Mitchell, 2025a)]]; [[08-Referencias#(Mitchell, 2025b)|(Mitchell, 2025b)]]. Esa ilusi√≥n de "chispas de razonamiento" es, en parte, lo que alimenta el furor actual en torno a estas tecnolog√≠as.

## 1.2 ¬øC√≥mo se construye la IA generativa?

La construcci√≥n de la IA generativa (para el caso de los LLM) se divide en dos grandes etapas: entrenamiento y postentrenamiento [[08-Referencias#(Karpathy, 2025)|(Karpathy, 2025)]]; [[08-Referencias#(Raschka, 2024a)|(Raschka, 2024a)]]. En la primera, el modelo se alimenta de enormes cantidades de texto (libros, art√≠culos, foros, sitios web) para aprender las estructuras b√°sicas del lenguaje: gram√°tica, vocabulario y relaciones entre palabras. Y se le pide la tarea aparentemente trivial pero fundamental: adivinar cu√°l es la siguiente palabra en una oraci√≥n. El resultado es un modelo base capaz de producir texto (es decir, recitar ‚Äútodo‚Äù el internet) pero a√∫n sin ‚Äúcomportarse‚Äù como un asistente conversacional. Por eso se realiza una segunda etapa, el postentrenamiento, que comienza con el ajuste fino supervisado (SFT). Aqu√≠, el modelo se entrena con conjuntos de datos m√°s peque√±os pero de alta calidad (conversaciones cuidadosamente dise√±adas), donde miles de etiquetadores humanos (o la misma IA generativa) crean pares de pregunta‚Äìrespuesta siguiendo instrucciones detalladas. Por ejemplo [[08-Referencias#(Penedo et al., 2024)|(Penedo et al., 2024)]]:

> Pregunta: ¬øEn qu√© se diferencia el trastorno bipolar de la depresi√≥n unipolar o la depresi√≥n com√∫n?¬†

> Respuesta: Tanto el trastorno bipolar como la depresi√≥n mayor suelen estar asociados a episodios depresivos. Por lo tanto, ambas enfermedades se acompa√±an de depresi√≥n. La diferencia radica en que en el trastorno bipolar las personas tambi√©n presentan per√≠odos de euforia o irritabilidad severa. A estos los llamamos episodios man√≠acos o hipoman√≠acos.¬†

De este modo, el modelo aprende no solo a generar texto, sino a comportarse como un asistente conversacional coherente al refinar el modelo base para seguir reglas conversacionales, sociales y ling√º√≠sticas aprendidas de humanos [[08-Referencias#(Ouyang et al., 2022)|(Ouyang et al., 2022)]].

Sin embargo, este ajuste fino no se limita a la imitaci√≥n. Suele incorporarse adem√°s el aprendizaje por refuerzo con retroalimentaci√≥n humana (RLHF), donde personas comparan varias respuestas del modelo, por lo que recibe retroalimentaci√≥n sobre cu√°les soluciones funcionan mejor, afinando m√°s la conducta del modelo de la siguiente manera: el modelo generativo produce varias respuestas a la misma indicaci√≥n (o prompt), personas las ordenan (por ejemplo: ‚Äúmejor, regular, peor‚Äù), y con esas comparaciones se entrena el modelo de recompensa (Reward Model, RM) para puntuar cada salida seg√∫n qu√© tanto coincide con lo que los humanos preferir√≠an. Despu√©s, el modelo generativo se vuelve a entrenar con aprendizaje por refuerzo para maximizar ese puntaje, en un ciclo an√°logo a ‚Äúprobar-equivocarse-ajustar‚Äù [[08-Referencias#(Ouyang et al., 2022)|(Ouyang et al., 2022)]]. A veces, en este proceso, surgen patrones de resoluci√≥n paso a paso (pasos intermedios, revisiones, comparaciones o autocorrecciones) que simulan razonamiento. Esta conducta, llamada chain-of-thought o ‚Äúcadena de pensamiento‚Äù [[08-Referencias#(Wei et al., 2023)|(Wei et al., 2023)]], se ha observado con fuerza en modelos recientes como DeepSeek R1 [[08-Referencias#(Guo et al., 2025)|(Guo et al., 2025)]], donde el refuerzo favorece secuencias largas y estructuradas que mejoran la precisi√≥n en problemas complejos. El modelo genera m√∫ltiples soluciones a un mismo problema y refuerza aquellas que conducen a buenos resultados.¬†

Todo este proceso de entrenamiento requiere recursos colosales: miles de unidades de procesamiento gr√°fico (GPU) trabajando durante semanas o meses, datasets filtrados y depurados y una ingenier√≠a cuidadosa [[08-Referencias#(Goodfellow et al., 2016)|(Goodfellow et al., 2016)]]. 

Una vez construidos los modelos generativos, estos se integran en sistemas, com√∫nmente en chatbots conversacionales capaces de mantener di√°logos, simular procesos de razonamiento, procesar millones de _tokens_ (fragmentos de texto) en segundos y generar textos con un nivel de coherencia que hace apenas unos a√±os resultaba impensable. Sin embargo, detr√°s de esa aparente ‚Äúmagia‚Äù hay estad√≠stica, matem√°ticas y computaci√≥n.

## 1.3 ¬øQu√© es un sistema de IA generativa?

Un Sistema de IA generativa es un entorno de software que articula interfaces, algoritmos y datos, combinando uno o varios modelos generativos para ofrecer servicios √∫tiles como chatbots conversacionales, buscadores que proporcionan respuestas resumidas, asistentes para generaci√≥n de c√≥digo o plataformas de creaci√≥n de im√°genes. Por ejemplo, ChatGPT es un chatbots que integra una interfaz conversacional con diferentes modelos GPT (actualmente GPT-5, GPT-5 Thinking o GPT-5 Pro), los cuales reciben un _prompt_ (una instrucci√≥n o consulta textual) y generan respuestas, im√°genes o c√≥digo en funci√≥n de esa entrada.

En sistemas cerrados como ChatGPT, Gemini o Grok, los modelos funcionan como cajas negras: no se conoce con exactitud qu√© datos fueron utilizados durante el entrenamiento ni los procesos aplicados en el postentrenamiento. Aunque es posible seleccionar la versi√≥n del modelo o modificar algunas configuraciones, el acceso al interior del modelo es restringido. Lo √∫nico que el usuario controla es la entrada (el prompt) y lo que recibe es la salida (la respuesta).

Esta limitaci√≥n dio origen a la _ingenier√≠a de prompts_ (ver cap√≠tulo siguiente): el arte de dise√±ar y perfeccionar instrucciones para guiar al modelo hacia respuestas precisas y √∫tiles (Boonstra 2025; Federiakin et al. 2024; Giray 2023; Lee et al. 2025; White et al. 2023). As√≠ que, sin acceso directo a los modelos, aprender a formular prompts efectivos se convierte en la estrategia clave para comunicarnos con ellos y aprovechar al m√°ximo sus capacidades.

## 1.4 Otros conceptos indispensables: Tokens, Ventana de Contexto y Memoria del Modelo

Para comprender un poco m√°s sobre el funcionamiento de los modelos generativos (LLM) y c√≥mo interactuamos con ellos, debemos conocer conceptos fundamentales que a menudo se comparan con la memoria humana: la _memoria de trabajo_ (de corto plazo) del modelo versus la _memoria de entrenamiento_ (conocimiento de largo plazo). Estas nociones se materializan en lo que se llama **ventana de contexto** y los par√°metros entrenados del modelo, respectivamente.

### 1.4.1 Tokens: La unidad b√°sica de procesamiento

Los modelos generativos (LLM) no leen palabras individualmente sino que las descomponen en piezas m√°s peque√±as llamadas **_tokens_**. Un token puede ser una palabra entera, un fragmento de palabra o un s√≠mbolo de puntuaci√≥n.

> [!EXAMPLE]+ Ejemplo de Tokenizaci√≥n 
> La frase _"¬øC√≥mo est√°s?"_ en espa√±ol puede descomponerse en 5 tokens [[08-Referencias#(Robles, 2025)|(Robles, 2025)]]:
> 
> - `¬ø`
> - `C√≥mo`
> - `est`
> - `√°s`
> - `?`

Cada modelo tiene su forma de tokenizar el texto (OpenAI, Google, Meta, etc., usan algoritmos de tokenizaci√≥n distintos), pero en promedio 1 token equivale a aproximadamente 3-4 caracteres (aunque var√≠a seg√∫n el idioma; en ingl√©s ~0.75 palabras por token, en espa√±ol un token suele representar algo menos que una palabra entera) [[08-Referencias#(Robles, 2025)|(Robles, 2025)]].

```mermaid
graph TD
    A[Texto: ¬øC√≥mo est√°s?] --> B[Tokenizaci√≥n]
    B --> C[Token 1: ¬ø]
    B --> D[Token 2: C√≥mo]
    B --> E[Token 3: est]
    B --> F[Token 4: √°s]
    B --> G[Token 5: ?]
    
    style A fill:#E8F4F8
    style B fill:#4A90E2,color:#fff
    style C fill:#98D8C8
    style D fill:#98D8C8
    style E fill:#98D8C8
    style F fill:#98D8C8
    style G fill:#98D8C8
```

Esto es importante porque tanto la entrada que proporcionamos al modelo como la salida que genera se miden en n√∫mero de tokens.

### 1.4.2 Ventana de Contexto: La Memoria de Trabajo

La ventana de contexto es la cantidad m√°xima de tokens que el modelo puede "tener en mente" o procesar a la vez en una interacci√≥n. Es an√°loga a la memoria de corto plazo humana: limita cu√°nta informaci√≥n previa el modelo puede recordar durante la generaci√≥n de una respuesta [[08-Referencias#(Robles, 2025)|(Robles, 2025)]].

> [!INFO]- ¬øQu√© Incluye la Ventana de Contexto? 
> En aplicaciones conversacionales, la ventana de contexto incluye:
> 
> - **Instrucciones del sistema**: Prompts ocultos que gu√≠an estilo y comportamiento
> - **Historial de la conversaci√≥n**: Todos los mensajes previos recientes
> - **Datos recuperados**: De bases de conocimiento (en enfoques RAG)
> - **Tu pregunta actual**: El nuevo mensaje del usuario
> - **La respuesta generada**: Los tokens que el modelo produce
> - **Marcas especiales de formato**: Delimitadores y metadatos
> 
> Todos estos elementos compiten por espacio en la ventana de contexto finita [[08-Referencias#(Robles, 2025)|(Robles, 2025)]].

Por ejemplo, un modelo con ventana de contexto de 4 mil tokens solo puede procesar esa cantidad entre la entrada del usuario y la respuesta generada. Si el contenido excede ese l√≠mite, el modelo truncar√° o ignorar√° el texto adicional, lo que resulta en p√©rdida de informaci√≥n.

> [!EXAMPLE] Ejemplo Pr√°ctico 
> Esto explica por qu√© no podemos simplemente darle _el texto completo de "Don Quijote" a ChatGPT-3.5_ (con ~4 mil tokens de contexto) y pedir un resumen, ya que superar√≠a su ventana y no podr√≠a ni leerlo [[08-Referencias#(Codificando Bits, 2023)|(Codificando Bits, 2023)]].

Debido a estas limitaciones, tambi√©n ha surgido la _ingenier√≠a de contexto_ como disciplina (como veremos m√°s adelante): decidir estrat√©gicamente qu√© informaci√≥n incluir o resumir en el prompt para aprovechar al m√°ximo la ventana limitada.

### 1.4.3 Memoria del Modelo (o de Entrenamiento): el Conocimiento a Largo Plazo

A diferencia de la memoria de trabajo acotada por la ventana de contexto, un modelo generativo posee una suerte de _memoria impl√≠cita de largo plazo_ derivada de su entrenamiento. Durante este proceso, el modelo ajusta miles de millones (o cientos de miles de millones en los modelos m√°s grandes) de par√°metros para codificar patrones ling√º√≠sticos y estructuras de pensamiento extra√≠dos de vastos corpus textuales: libros, art√≠culos cient√≠ficos, entre otros.

Esto significa que gran parte del conocimiento est√° almacenado en el modelo tras el entrenamiento, an√°logo a conocimientos que un humano almacena en su memoria a largo plazo. Por ejemplo, GPT-3 se entren√≥ con ~45 terabytes de texto y alcanz√≥ 175 mil millones de par√°metros, incorporando as√≠ enormes cantidades de informaci√≥n general en sus "pesos"(datos hasta ~2021)  [[08-Referencias#(Amazon Web Services, s. f.)|(Amazon Web Services, s. f.)]].

```mermaid
graph TB
    A[Modelo de Lenguaje] --> B[Ventana de Contexto<br/>Memoria de Trabajo]
    A --> C[Par√°metros Entrenados<br/>Memoria de Largo Plazo]
    
    B --> D[Limitada: 4K - 2M tokens]
    B --> E[Informaci√≥n actual<br/>de la conversaci√≥n]
    B --> F[Se resetea cada sesi√≥n]
    
    C --> G[Masiva: Billones de par√°metros]
    C --> H[Conocimiento general<br/>hasta fecha de corte]
    C --> I[Permanente pero imperfecta]
    
    style A fill:#4A90E2,color:#fff
    style B fill:#98D8C8
    style C fill:#F5A623
    style D fill:#E8F4F8
    style E fill:#E8F4F8
    style F fill:#E8F4F8
    style G fill:#FEF5E7
    style H fill:#FEF5E7
    style I fill:#FEF5E7
```

> [!WARNING]+ No es una memoria perfecta 
> Esta memoria de entrenamiento no es perfecta ni organizada:
> 
> - Los modelos generativos no recuerdan datos concretos
> - Generan respuestas basadas en patrones estad√≠sticos
> - A veces "recuerdan" con exactitud sorprendente (definiciones, c√≥digo conocido, citas)
> - Otras veces confabulan detalles incorrectos si no "memorizaron" ese dato con fidelidad

Investigaciones muestran que los modelos pueden llegar a memorizar trozos exactos de sus datos de entrenamiento, especialmente aquellos √∫nicos o repetitivos [[08-Referencias#(Zia, 2025)|(Zia, 2025)]]. Esto plantea riesgos: un modelo puede sin querer revelar informaci√≥n sensible presente en sus datos de entrenamiento (por ejemplo, fragmentos de c√≥digo propietario o informaci√≥n personal) si se le induce correctamente [[08-Referencias#(Zia, 2025)|(Zia, 2025)]].

> [!TIP] Diferencia Clave 
> **Ventana de contexto** = Lo que el modelo puede ver y recordar _en este instante_  
> **Conocimiento entrenado** = Todo lo que aprendi√≥ (hasta su fecha de corte de entrenamiento)

### 1.4.4 ¬øPor qu√© importan tanto estos l√≠mites?

Porque determinan lo que el modelo puede y no puede hacer con la informaci√≥n:

- Si nuestra pregunta requiere m√°s contexto del que cabe en su ventana, tendremos que resumir o partir la tarea.
- Si preguntamos sobre hechos posteriores a la fecha de entrenamiento, el modelo posiblemente no lo sepa a menos que se lo proporcionemos en el prompt.
- Muchos sistemas actuales combinan modelos generativos con herramientas externas (b√∫squedas en internet, bases de conocimiento actualizadas) para recuperar datos frescos.

## 1.5 Algunos puntos cr√≠ticos de la IA

Por supuesto, los LLM no son infalibles. Una limitaci√≥n conocida son las ‚Äúalucinaciones‚Äù: respuestas inventadas que suenan plausibles pero son falsas [[08-Referencias#(Ji et al., 2023)|(Ji et al., 2023)]]. Esto ocurre porque el modelo, al haber sido entrenado para ‚Äúresponder siempre‚Äù, tiende a completar patrones ling√º√≠sticos incluso cuando no tiene informaci√≥n suficiente. Las empresas han tratado de reducir este problema incluyendo ejemplos donde la respuesta correcta es ‚Äúno lo s√©‚Äù y, en versiones m√°s avanzadas, permitiendo que el modelo use herramientas externas (como motores de b√∫squeda o int√©rpretes de c√≥digo) para consultar informaci√≥n o realizar c√°lculos exactos. De esta forma, los modelos modernos combinan memoria de entrenamiento con memoria de trabajo y acceso a herramientas externas, acerc√°ndose cada vez m√°s a lo que pareciera una inteligencia funcional e h√≠brida.

Tambi√©n est√°n los sesgos, que no s√≥lo reflejan prejuicios existentes en los datos de entrenamiento, sino que pueden amplificarse a trav√©s de los propios sistemas. Un estudio reciente en _Nature_ (8 de octubre de 2025) muestra que, en casi 1.4 millones de im√°genes y videos de la web y en nueve modelos de lenguaje, las mujeres tienden a ser representadas o inferidas por los modelos como m√°s j√≥venes que los hombres; la brecha es mayor en ocupaciones de mayor estatus e ingresos.¬† Este trabajo tambi√©n documenta ‚Äúamplificaci√≥n algor√≠tmica‚Äù: al buscar im√°genes de ocupaciones en Google, aumentan los sesgos edad-g√©nero en las creencias y preferencias de contrataci√≥n de las personas, y al generar/evaluar curr√≠culums, ChatGPT asume con mayor frecuencia que las mujeres son m√°s j√≥venes y menos experimentadas, valorando mejor a varones de mayor edad https://www.nature.com/articles/s41586-025-09581-z?s=08.

 Por lo tanto, una IA sin gobernanza puede magnificar estos sesgos y salidas da√±inas como lenguaje de odio, aumentar la opacidad y concentrar poder; por ello, se recomiendan documentaci√≥n rigurosa de datos y modelos, evaluaciones de riesgo y mecanismos de rendici√≥n de cuentas [[08-Referencias#(Bender et al., 2021)|(Bender et al., 2021)]]; [[08-Referencias#(Bengio et al., 2025)|(Bengio et al., 2025)]]. De ah√≠ que sea importante la alfabetizaci√≥n cr√≠tica, para conocer lo que los modelos hacen y no hacen, insistir en mantener humanos en el proceso de su creaci√≥n para verificar, contextualizar y decidir, as√≠ como empoderar a m√°s personas (docentes, estudiantes, periodistas, funcionariado y ciudadan√≠a) para entender y usar la IA con juicio informado y responsable [[08-Referencias#(Mitchell, 2019)|(Mitchell, 2019)]]; [[08-Referencias#(Mitchell y Krakauer, 2023)|(Mitchell y Krakauer, 2023)]].



 (ver [[#^fig1|Figura 1]])

<div align="center">
<img src="Benchmarks.png" style="width:80%">
</div>
 **Figura 1.** Descripci√≥n detallada de la imagen
^fig1



> [!TIP] Pr√≥ximo Paso 
> Ahora que comprendemos los fundamentos t√©cnicos, estamos listos para aprender el arte de comunicarnos eficazmente con estos sistemas. En el siguiente cap√≠tulo abordaremos la **Ingenier√≠a de Prompts**: la habilidad clave para transformar nuestras ideas en resultados precisos mediante instrucciones bien dise√±adas.

---

**üß≠ Navegaci√≥n:** [[00-Prefacio|‚¨ÖÔ∏è Prefacio]] | [[02-Ingenier√≠a-Prompts|Siguiente: Cap√≠tulo 2 ‚û°Ô∏è]]

---

<div align="center">
  <img src="../recursos/logos/SocialData.svg" alt="SocialData Logo" style="height:60px; margin: 0 15px;">
  <img src="../recursos/logos/EducaIA.svg" alt="EducaIA Logo" style="height:60px; margin: 0 15px;">
</div>
